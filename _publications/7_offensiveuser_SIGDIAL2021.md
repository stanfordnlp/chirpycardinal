---
title: Large-Scale Quantitative Evaluation of Dialogue Agents’ Response Strategies against Offensive Users
link: "/assets/pdf/HandlingOffensiveUsers_SIGDIAL.pdf"
authors: Haojun Li, Dilara Soylu and Christopher D. Manning
venue: Special Interest Group on Discourse and Dialogue (SIGDIAL), 2021
---
As voice assistants and dialogue agents grow in popularity, so does the abuse they receive.  We conducted a large-scale quantitative evaluation of the effectiveness of 4 response types (avoidance, why, empathetic, and counter), and 2 additional factors (using a redirect or a voluntarily provided name) that have not been tested by prior work.  We measured their direct effectiveness on real users in-the-wild by the re-offense ratio, length of conversation after the initial response, and number of turns until the next re-offense. Our experiments confirm prior lab studies in showing that empathetic responses perform better than generic avoidance responses as well as counter responses. We show that dialogue agents should almost always guide offensive users to a new topic through the use of redirects and use the user’s name if provided.  As compared to a baseline avoidance strategy employed by commercial agents, our best strategy is able to reduce the re-offense ratio from 92% to 43%.
